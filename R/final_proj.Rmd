---
title: "EDS 222: Final Project"
author: "Carly Caswell"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load all the packages needed here
library(tidyverse) #for tidying my data
library(readr)
library(gt)
library(tufte)
library(dplyr) #for wrangling
library(dotwhisker) #for pretty plotting
library(plotly) #for plotting
library(lubridate) #for extracting specific years in the data
library(sf)
library(ggmap)
library(tmap)
library(here)

# Set your filepath here! Or, set this up as an .Rproj if you'd like.
rootdir <- ("~/Documents/MEDS/Fall_Q2/EDS-222-Stats/Assignments")
datadir <- file.path(rootdir,"eds222-final","data")
```

ABOUT:

I am interested in the relationship between temperature changes and snowfall trends due to climate change. Are seasonal temperature differences causing snowfall patterns later in the year (ski resorts opening later or earlier) in New England? Was this past year statistically significant given what the west coast saw in terms of trends?

Snowfall also largely helps water sources in the spring, as an example, it provides 75% of the water supply for Western states populations

With this preliminary analysis, I hope to better predict future snowfall trends. This could help inform ski resorts or other winter-seasonal dependent industries. This could also help determine....

DATA:

<https://nwcc-apps.sc.egov.usda.gov/site-plots/#VT>

Dataset 1 - Titled "xyz" dataset called, this contains x,y, z and comes from SOURCE. I will primarily be using variables a,b,c, which contain ...... "the mean number of days with minimum temperature below freezing (mean over the years 2020-2022)." <https://ourworldindata.org/covid-cases>

Dataset 2 - Titled "xyz" dataset from COUNTRY. These data were obtained from the [ERA5 database](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5), a product made available by the European Centre for Medium-Range Weather Forecast. The high-resolution hourly gridded data were aggregated to the municipality by month level -- that is, each observation in these data report a monthly average temperature value and a monthly cumulative precipitation value for one of the 1,123 municipalities across the country.[\^3]

```{r}
# Reading in the data:
vt_temps <- read_csv(file.path(datadir,"Mount_Mansfield_temps.csv"))    
vt_snow <- read_csv(file.path(datadir,"Mount_Mansfield_snow.csv"))

```

EXPLORATION & WRANGLING:

Let's look at the temperature data first:

```{r}
#Let's take a look at some of this data further:
head(vt_temps)

#Making this data tidy:
tidy_vt_temps <- vt_temps %>%
  pivot_longer(cols = c('2001', '2002', '2003', '2004', '2005', '2006', '2007', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2021', '2022', '2023'), names_to = "year", values_to = "value") %>% 
  select(-'2009', -'2010', -'2019', -'2024') 

#creating a combined date column
tidy_vt_temps$date <- paste(tidy_vt_temps$year, tidy_vt_temps$date, sep = "-")
class(tidy_vt_temps$date) #it's still a character so this needs to be updated
tidy_vt_temps$date <- ymd(tidy_vt_temps$date)
class(tidy_vt_temps$date) #nice, it's now a date column

#Plotting a few years of data:
ggplot(tidy_vt_temps, aes(x = date, y = value)) +
  geom_line()

#I've decided I want to compare months November - March from years 2002 to 2022 (10 years)

#Filter for only the months I want:
tidy_vt_temps_winter <- tidy_vt_temps_winter %>% 
   mutate(month = month(date)) %>% 
  filter(month(date) %in% c(11, 12)) %>% 
  rename(temp = value)


#Calculating the mean and standard dev for the temps for each month each year:
temp_monthly_stats = tidy_vt_temps_winter %>% 
  group_by(year, month(date)) %>% 
  summarize("Monthly_Mean" = round(mean(value, na.rm = TRUE), 2), "Monthly_SD" = round(sd(value, na.rm = TRUE), 2))

#Reviewing the results table:
print(temp_monthly_stats)
#The year with the highest mean and variance in number of cases is 2022.
```

Now looking at the snowfall data:

```{r}
#Let's take a look at some of this data further:
head(vt_snow)

#Making this data tidy:
tidy_vt_snow <- vt_snow %>%
  pivot_longer(cols = c('2001', '2002', '2003', '2004', '2005', '2006', '2007', '2011', '2012', '2013', '2015', '2016', '2017', '2018', '2022', '2023'), names_to = "year", values_to = "value") %>% 
  select(-'2009', -'2010', -'2020', -'2024') 

#creating a combined date column
tidy_vt_snow$date <- paste(tidy_vt_snow$year, tidy_vt_snow$date, sep = "-")
class(tidy_vt_snow$date) #it's still a character so this needs to be updated
tidy_vt_snow$date <- ymd(tidy_vt_snow$date)
class(tidy_vt_snow$date) #nice, it's now a date column

#Plotting a few years of data:
ggplot(tidy_vt_snow, aes(x = date, y = value)) +
  geom_line()

#I've decided I want to compare months November - March from years 2002 to 2022 (10 years)

#Filter for only the months I want:
tidy_vt_snow_winter <- tidy_vt_snow %>% 
  filter(month(date) %in% c(11, 12, 1, 2, 3)) %>% 
  mutate(month = month(tidy_vt_snow_winter$date)) %>% 
  rename(snowfall = value)

#Calculating the mean and standard dev for the snowfall in inches for each month each year:
snow_monthly_stats = tidy_vt_snow_winter %>% 
  group_by(year, month(date)) %>% 
  summarize("Monthly_Mean" = round(mean(value, na.rm = TRUE), 2), "Monthly_SD" = round(sd(value, na.rm = TRUE), 2))

#Reviewing the results table:
print(snow_monthly_stats)
#The year with the highest mean and variance in number of cases is 2022.
print(max(snow_monthly_stats$Monthly_Mean, na.rm = TRUE))
```

```{r}
#Just getting the years I want to compare:
tidy_vt_snow_winter_years <- tidy_vt_snow_winter %>% 
  filter(year %in% c('2002','2022') & month %in% c(11,12)) %>% 
  mutate( month_day = sprintf("%02d-%02d", month(date), day(date)))
```

```{r}
tidy_vt_test <- 
tidy_vt_snow_winter %>% 
   filter(month %in% c(11,12)) %>% 
  mutate(month_day = sprintf("%02d-%02d", month(date), day(date)))
```

#ANALYSIS

Now that I have all my data, I can plot it together to get a visual comparison of years:

```{r}
#graph depicting annual snowfall from....
#describe the pattern
ggplot(tidy_vt_snow_winter_years, aes(x= value, color = as.factor(year))) +
  geom_bar(size = 2) +
  theme_minimal()


ggplot(tidy_vt_snow_winter_years, aes(x = month_day, y = value, group = year, color = as.factor(year))) +
  geom_line(size = 1) +
  labs(title = "Comparison of Snowfall on Mount Mansfield from 2002 to 2022",
       x = "Dates",
       y = "Snowfall (in inches)",
       color = "Year") +
  scale_color_manual(values = c("2002" = "blue", "2022" = "lightblue")) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
plot_ly(tidy_vt_test, 
        x = ~month_day, 
        y = ~value, 
        color = ~as.factor(year), 
        type = "scatter",
        mode = "lines+markers",
        line = list(width = 1)) %>%
  layout(title = "Comparison of Snowfall on Mount Mansfield from 2002 to 2022",
         xaxis = list(title = "Dates"),
         yaxis = list(title = "Snowfall (in inches)"),
         legend = list(title = "Year"))
```

**I see a mostly positive/negative relationship between y in units and x. The correlation seems to be mostly strong with a few outliers that could have an impact on the overall correlation coefficient.**

**I think this relationship makes intuitive sense because the higher the temperature the drier and more fire-prone conditions there will be.**

```{r}
#printing the mean, min, and max for the sample years for November and December

 summarize(mean = mean(PM, na.rm = TRUE),
            min = min(PM, na.rm = TRUE),
            max = max(PM, na.rm = TRUE))
```

Describing the two years differences

I am aiming to draw conclusions about the Vermont snow climate using this sample from Mount Mansfield of temperature and snowfall observations.

```{r}
vt_hist <-
  ggplot(tidy_vt_snow_winter) +
  geom_histogram(aes(x = value))
vt_hist
```

\*\*This data is skewed to the right. There is a right long tail. This distribution is unimodal.\*\*

```{r}
vt_temp_hist <-
  ggplot(tidy_vt_temps_winter) +
  geom_histogram(aes(x = value))
vt_temp_hist
```

\*\*This data is symmetric. This distribution looks approximately normally distributed. This distribution is unimodal.\*\*

Now I'm going to look at the temperature and snowfall by splitting my data. Since I have years of data from 2002 - 2022, with a few years missing data, I want to bucket more recent years to years farther in the past. For this example, I'm going to bucket my data to look at the years 2015,2016,2022 (recent) and 2001, 2002, and 2003 (non-recent).

One big challenge here was the fact that we had quite limited data for many years, with some years not even being in the dataset. There was not information on the website about why there were years missing or there were many NAs, so I was limited to working with the years that did have complete data

```{r}
# I'm going to join the two datasets together first:
vt_data <- merge(tidy_vt_snow_winter, tidy_vt_temps_winter, by = 'date')

#taking a look at the data:
vt_data <- vt_data %>% 
  select(-"Min.x", -"10%.x",-"30%.x", -"70%.x", -"90%.x", -"Max.x", -"Median (POR).x", -"year.x", -"month.x", -"Min.y",-"10%.y", -"30%.y",-"70%.y",-"90%.y",-"Max.y",-"Median (POR).y") %>% 
  rename(year = "year.y", month = "month.y")
vt_data

#Summarizing the snowfall and temperature data for recent years:
vt_recent <- 
  vt_data %>% 
  filter(year %in% c('2015', '2016', '2022')) %>% 
summarise(snow_mean = mean(snowfall, na.rm = TRUE), snow_sd = sd(snowfall, na.rm = TRUE), snow_median = median(snowfall, na.rm = TRUE),temp_mean = mean(temp, na.rm = TRUE), temp_sd = sd(temp, na.rm = TRUE), temp_median = median(temp, na.rm = TRUE))

#visualizing the data:
vt_recent

#Summarizing the snowfall and temperature data before for non-recent years:
vt_non_recent <- 
  vt_data %>% 
  filter(year %in% c('2001', '2002', '2003')) %>% 
summarise(snow_mean = mean(snowfall, na.rm = TRUE), snow_sd = sd(snowfall, na.rm = TRUE), snow_median = median(snowfall, na.rm = TRUE),temp_mean = mean(temp, na.rm = TRUE), temp_sd = sd(temp, na.rm = TRUE), temp_median = median(temp, na.rm = TRUE))

#visualizing the data:
vt_non_recent
```

Snowfall Table:

| Years                         | Mean (inches) | Standard Deviation (inches) | Median (inches) |
|------------------------|------------|-----------------|---------------|
| Recent (2015,2016, 2022)      | 2.78          | 3.65                        | 1               |
| Non-Recent (2001, 2002, 2003) | 7.73          | 7.15                        | 6               |

Temperature Table:

| Years                         | Mean (F) | Standard Deviation (F) | Median (F) |
|------------------------|------------|-----------------|---------------|
| Recent (2015,2016, 2022)      | 30.04    | 10.19                  | 30.2       |
| Non-Recent (2001, 2002, 2003) | 26.11    | 12.14                  | 26.6       |

```{r}
ggplot(vt_data, aes(sample = snowfall)) +
  geom_qq() +
  geom_qq_line() +
  ggtitle("Q-Q Plot for Snowfall")
```

```{r}
#QQ Plot for Temperature
ggplot(vt_data, aes(sample = temp)) +
  geom_qq() +
  geom_qq_line() +
  ggtitle("Q-Q Plot for Temperature")
```

```{r}
log_snowfall <-exp(vt_data$snowfall)
ggplot(vt_data, aes(sample = log_snowfall)) +
  geom_qq() +
  geom_qq_line() +
  ggtitle("Q-Q Plot for Transformed Precipitation Data")
```

I can now run a hypothesis test to see if there is no difference in means from my recent sample group and my non-recent sample group.

MY QUESTION:

Is the mean snowfall in inches different in the recent years than in previous years?
Is the mean temperature days below freezing different in recent years than in previous years?

My null and alternative hypotheses:

$$H_{O}: \mu_{recent} - \mu_{nonrecent} = 0$$

$$H_{A}: \mu_{recent} - \mu_{nonrecent} \neq 0$$

```{r}
#Running a t.test on the filtered data:
t.test(Frost ~ state.region, data = filtered_state_frost, conf.level = 0.95)

#Construct a 95% confidence interval for your slope coefficient:
conf_interval <- confint(murders, level = .95)[2, ] #using the confint function

print(paste('I am 95% confident the range', round(conf_interval[1], 3), 'and',  round(conf_interval[2], 3), 'contains the true population difference between murder rates per 100,000 people and average number of frost days between 1931 and 1960.'))

```


Is there a statistically significant relationship between frost days on murder rates? At what significant level is this effect significant?

**Yes, p value is .00005 with a significance level of .05 so this proves that there is a significant relationship between Frost days and murder rates**

**The p-value is just slightly different than the manual calculation, but I still end up with the same conclusion (reject the null). This is what I'd expect since I'm using a q normal distribution in my manual approach and a t distribution in the function approach.**




Additional potential analysis:

```{r}
#Create a basemap of New England and show the rate of change of snowfall from x year to y year 
#columns would be: lat, long, rate of change
#figure out how to make the bubble plot

data <- data.frame(lat = c(41.77, 41.82, 44.47, 42.93, 43.65, 42.38), 
                   long =c(-70.67, -89.97, -83.72, -78.73, -97.78, -72.53),
                   trend = c(0.407, 0.136, -0.185, 0.543, 0.21, -0.182))

ne <- st_read(here('./data/NEWENGLAND_POLY.shp'))

sf_data <- st_as_sf(data, coords = c("long", "lat"), crs = 4326)

data2 = data("us", package = "sf")
tm_shape(ne$FIPS) +
 # tm_shape(data)+
  #tm_bubbles(size = "trend", col = "red", alpha = 0.7) +
  tm_basemap(server = "OpenStreetMap")
  tm_layout(title = "Trend Map of New England", width = 800, height = 600)
```

```{r}
plot(ne)
```

#Map snow depth locations and a topographic map of vermont?
#monthly mean snow depth between 1971 and 2019
#showed decreases in snow depth for most stations from November to May.

Show a topographic map of vermont with Stowe/Mount Mansfield
